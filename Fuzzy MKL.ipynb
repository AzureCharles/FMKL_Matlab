{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8df50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "class deepMKL(nn.Module):\n",
    "    def __init__(self, input_size, output_size, n_layers=3):\n",
    "        super(deepMKL, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.betas = nn.Parameter(torch.ones(n_layers, 4) / 4)\n",
    "\n",
    "    def forward(self, x, sig):\n",
    "        Kf = []\n",
    "        for i in range(self.n_layers):\n",
    "            beta = self.betas[i]\n",
    "            k = torch.exp(-torch.sum((x.unsqueeze(1) - x.unsqueeze(2)) ** 2, dim=-1) / (2 * sig ** 2))\n",
    "            Kf.append(torch.matmul(k, beta))\n",
    "            x = Kf[-1]\n",
    "        return Kf, torch.matmul(Kf[-1], Kf[-1].t())\n",
    "\n",
    "    def train(self, x, y, lr=1e-4, max_iter=100, c=10):\n",
    "        n_samples = x.shape[0]\n",
    "        dotx = torch.matmul(x, x.t())\n",
    "        sig = self._determine_sig(dotx.numpy())\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        span = 0\n",
    "        for t in range(max_iter):\n",
    "            Kf, Ks = self.forward(x, sig)\n",
    "            model = SVC(C=c, kernel='precomputed')\n",
    "            model.fit(Ks.numpy(), y.numpy())\n",
    "\n",
    "            if self.n_layers == 1:\n",
    "                grad, span_t = self._grad_1_layer(model, Kf[0], y)\n",
    "            elif self.n_layers == 2:\n",
    "                grad, span_t = self._grad_2_layer(model, Kf[0], Kf[1], sig, y)\n",
    "            elif self.n_layers == 3:\n",
    "                grad, span_t = self._grad_3_layer(model, Kf[0], Kf[1], Kf[2], sig, y)\n",
    "\n",
    "            self.betas.data -= lr * grad\n",
    "            self.betas.data[self.betas.data < 0] = 0\n",
    "            if self.betas[-1].sum() > 1:\n",
    "                self.betas[-1] /= self.betas[-1].sum()\n",
    "\n",
    "            if np.isnan(self.betas.numpy().sum()):\n",
    "                raise ValueError('Learning rate is too high')\n",
    "            elif t > 5 and abs(span - span_t) < 1e-4:\n",
    "                break\n",
    "            span = span_t\n",
    "\n",
    "    def _determine_sig(self, dotx):\n",
    "        n = dotx.shape[0]\n",
    "        s = np.median(dotx)\n",
    "        return np.sqrt(s / 2)\n",
    "\n",
    "    def _grad_1_layer(self, model, Kf, y):\n",
    "        K = torch.exp(-torch.sum((Kf.unsqueeze(1) - Kf.unsqueeze(2)) ** 2, dim=-1) / (2 * self.sig ** 2))\n",
    "        y_pred = torch.from_numpy(model.decision_function(K.numpy())).float()\n",
    "        grad = torch.zeros_like(self.betas)\n",
    "        for i in range(self.n_layers):\n",
    "            grad[i, 0] = torch.sum(Kf[i] * (1 - y * y_pred))\n",
    "            grad[i, 1] = torch.sum(Kf[i] * (1 -\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
